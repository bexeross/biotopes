---
title: "megaTwin deep summaries - R Notebook"
output: html_notebook
---
USE WITH PROVISIONAL CLASS ALLOCATIONS

As even splitting into smaller twintables can result in some being too big to digest, we want to try and dplyr::summarise groups at different levels for their average pseudospp., n, max pseudospp? to be better able to compare sub-branches.

#NB
If you came from 4a_megaTwinDeepSummaries_Vclasses.RMD then you have already done the first few steps and just need to slot in the object you made in that script around line 114 (search for title "If you came from 4a_megaTwinDeepSummaries_Vclasses.RMD " to find your starting point.)

#library
```{r}
library(twinspan)
library(dplyr)
library(tibble)
library(Matrix)
```

#provisional classes
likely identified from the heatmap analysis. These will be labelled from 1 (left) to n with the prefix listed below (currently "V").
```{r}
# # Set number of classes needed
# n<-19
# 
# # Make reclassification table
# reclassify <- data.frame(level=c(6,6,4,5,7,8,8,6,5,5,4,5,6,6,5,5,4,1,5),
#                          class=c(71,70,16,36,148,298,299,75,38,39,23,45,89,88,40,41,21,3,34),
#                          new_class=sprintf("V%s",seq(1:n)))


# #Pål classes
# n<-26
# 
# # Make reclassification table
# reclassify <- data.frame(level=c(6,6,5,4,7,7,6,7,8,8,6,5,5,4,5,6,6,6,6,7,7,5,6,6,1,6),
#                          class=c(71,70,34,16,147,146,72,148,298,299,75,38,39,23,45,89,88,81,80,164,165,43,84,85,3,83),
#                          new_class=sprintf("P%s",seq(1:n)))


# The 64 (Decemeber 2021 delivery)
# n<-64
# 
# #Pål class subclasses (after first analysis)
# reclassify<-data.frame(level=c(7,7,6,6,7,7,4,7,7,6,8,8,8,8,6,6,7,7,7,7,7,8,8,5,6,6,7,7,7,8,8,6,7,8,9,9,4,7,7,7,10,10,9,10,10,9,8,8,7,7,7,8,8,9,9,9,9,8,8,9,9,8,2,2),
#                          class=c(142,143,70,68,138,139,16,147,146,72,296,297,298,299,75,76,154,155,157,156,158,318,319,46,94,95,180,181,182,366,367,89,176,354,710,711,20,166,167,164,1320,1321,661,1324,1325,663,344,345,173,174,175,336,337,676,677,678,679,343,340,682,683,342,6,7
# ),
# new_class=sprintf("P%s",seq(1:n)))

# Jan 2022 new data added - tw_2
n<-64

#Pål class subclasses (after first analysis)
reclassify<-data.frame(level=c(7,7,6,6,7,7,4,7,7,6,8,8,8,8,6,6,7,7,7,7,7,8,8,5,6,6,7,7,7,8,8,6,7,8,9,9,4,7,7,7,10,10,9,10,10,9,8,8,7,7,7,8,8,9,9,9,9,8,8,9,9,8,2,2),
                         class=c(142,143,70,68,138,139,16,147,146,72,296,297,298,299,75,76,154,155,157,156,158,318,319,46,94,95,180,181,182,366,367,89,176,354,710,711,20,166,167,164,1320,1321,661,1324,1325,663,344,345,173,174,175,336,337,676,677,678,679,343,340,682,683,342,6,7
),
new_class=sprintf("P%s",seq(1:n)))


```


# matrix
we need the twintable matrix to work with, which we can get with twin2mat and this needs to be merged with res
```{r}
tw_1.df<-rownames_to_column(as.data.frame(twin2mat(tw_1)))


#make res again if need be
res<-data.frame(SampID = samples, level1 = NA, level2= NA, level3 = NA, level4 = NA, level5 = NA, level6 = NA, level7 = NA, level8= NA, level9 = NA, level10 = NA, level11 = NA, level12 = NA, level13 = NA, level14= NA, level15 = NA)
 
 for(i in 1:15){
   res[,i+1]<-cut(tw_1, level = i)
 }
 
 f = function(x) length(unique(x))
 lapply(res, FUN = f)
 
#join together
res.mat<-left_join(res, tw_1.df, by = c("SampID"="rowname"))
res.matREF<-res.mat

rownames(res.mat) <- res.mat[,1]
```

# Reclassify dataset
```{r}
# Reclassify
for(i in 1:n){
  res.mat[getsamplesingrp(res.matREF,reclassify$level[i],reclassify$class[i]),"class"]<-as.character(reclassify$new_class[i])
}

table(res.mat$class)

#my.subs<-res.mat
#

```


##order levels
```{r}
class.ls<-c("P1","P2","P3","P4","P5","P6","P7","P8","P9","P10",
            "P11","P12","P13","P14","P15","P16","P17","P18","P19","P20",
            "P21","P22","P23","P24","P25","P26","P27","P28","P29","P30",
            "P31","P32","P33","P34","P35","P36","P37","P38","P39","P40",
            "P41","P42","P43","P44","P45","P46","P47","P48","P49","P50",
            "P51","P52","P53","P54","P55","P56","P57","P58","P59","P60",
            "P61","P62","P63","P64")
res.mat$class <- factor(res.mat$class, levels = class.ls)

clss.ref.mat<-res.mat
```


# If you came from 4a_megaTwinDeepSummaries_Vclasses.RMD

You can start here - you have a "my.subs" object that is in the right format already (which, if you came from NEWDATA_4_compareNew2Old_twinspan.RMD was originally called my.subs.tw2) we just need to convert this to a new object to be the master reference sheet as the my.subs name is being used again (being "my subset").

```{r}
clss.ref.mat<-my.subs.tw2
```



# Add trawl data
```{r}
#merge trawl mark data (make ure you have run "data_prep_trawlmarks.Rmd" first) Need to do this after summarising env var as there are too many NAs in trawl marks to get goo summaries
trawlwide.cln<-trawlwide %>%
  group_by(SampID) %>%
  summarise(TrawlmarkDens=max(`Trawl mark`))


clss.ref.mat<- clss.ref.mat %>%
  left_join(., trawlwide.cln, by =c("SampID"="SampID"))%>%
  replace(is.na(.), 0)
```

______________

#SECTION YOU EDIT

Edit the class and level here and run all chunks below to output the 3 summary csvs.
```{r}
my.class<-"Tmp9"
deep.level<-"level11"
```
______________



# select class to subset & level to subgroup

CURRENTLY QUITE MANUAL, LOOK INTO AUTOMATING FURTHER
i.e. subset to class, look for level at which there become multiple group numbers, then use 2?/3? levels below that for groups (could use "reclassify" look up table to find the same class, look for the cut level and add 2?)

```{r}
#my.subs<-subset(res.mat,class =="P26") #change as needed
#my.subs<-subset(res.mat,is.na(class)) #change as needed
my.subs<-subset(clss.ref.mat,class ==my.class) #change as needed
```


# pivot at given class level

## metadata
Make table of metadata (parent groups, n sub groups at level 15, and n samples per group)

```{r}
#parent groups
piv.meta.a<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  dplyr::summarise(across(c(2:15),mean)) %>%
  t()%>%
  `colnames<-`(.[1, ])%>%
  .[-1, ]

# n lev 15 groups
piv.meta.15<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  dplyr::summarise(nSubGpL15 = n_distinct(level15)) %>%
  t()%>%
  as.data.frame() %>%
  `colnames<-`(.[1, ])%>%
  .[-1, ]

# n samples
piv.meta.g<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  summarise(nSamp=n_distinct(SampID),
            trawlm_Max=max(TrawlmarkDens)) %>%
  t()%>%
  as.data.frame() %>%
  `colnames<-`(.[1, ])%>%
  .[-1, ]%>%
  type.convert()


piv.meta<-rbind(piv.meta.a,piv.meta.15,piv.meta.g)
```

## full summary dataset
Make tables of average psuedospp per class/proportion of obs per class/max pseudospp per class

*Average pseudospp*
```{r}
piv.av<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  dplyr::summarise(across(c(17:343),mean)) %>%
  t()%>%
  `colnames<-`(.[1, ])%>%
  .[-1, ] %>%
  type.convert()

#piv.av[,] <- sapply(piv.av[,], as.numeric)


round_df <- function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}

piv.av<-round_df(piv.av, 1)
```

*proportion obs*
i.e. proportion of n spp obs (non zero pseudospp)/n samples per group
```{r}
piv.n<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  dplyr::summarise(across(c(17:343),nnzero)) %>%
  t()%>%
  as.data.frame() %>%
  `colnames<-`(.[1, ])%>%
  .[-1, ] %>%
  type.convert()

#piv.meta.g[,] <- sapply(piv.meta.g[,], as.numeric)
#piv.n[,] <- sapply(piv.n[,], as.numeric)
piv.meta.gn<-as.data.frame(piv.meta.g[1,])

piv.prop<-mapply('/',piv.n,piv.meta.gn)
rownames(piv.prop)<-rownames(piv.n)
piv.prop<-round_df(piv.prop,2)

```

*Max pseudospp*
Make table of maximum pseudospp per group
```{r}
piv.mx<-my.subs %>%
  group_by(.data[[deep.level]])%>% # change to level you want to see groups at
  dplyr::summarise(across(c(17:343),max)) %>%
  t()%>%
  `colnames<-`(.[1, ])%>%
  .[-1, ]
```

Combine for outputting
```{r}
out.piv<-cbind(piv.av, piv.prop, piv.mx)
values<-c(rep("av",ncol(piv.av)), rep("prop",ncol(piv.prop)), rep("max", ncol(piv.mx)))

out.piv<-rbind(values, out.piv)
```

## short form summary
I.e. dominant spp (av >1pseudospp) and consistent spp (present in >50% samples).

*Dominant*
```{r}
dom.av<-piv.av%>%
  as.data.frame() %>%
  filter_all(any_vars(. > 1))%>%
  rownames_to_column("taxa")
```

*Consistent*
```{r}
hi.prop<-piv.prop%>%
  as.data.frame() %>%
  filter_all(any_vars(. > 0.5))%>%
  rownames_to_column("taxa")
```

combine

```{r}
#short.sum<-cbind(dom.av,hi.prop)
short.sum<-dom.av%>%
  full_join(hi.prop, by=c("taxa"="taxa"))
values2<-c(rep("av>1",ncol(dom.av)), rep("prop>.5",ncol(hi.prop)))

out.piv.short<-rbind(values2, short.sum)
```




#output csvs

```{r}

 write.csv(out.piv.short, 
           file = file.path(outPath,paste(my.class,"_avGT1_propGT50pc.csv"))) #change label


write.csv(out.piv, 
          file = file.path(outPath,paste(my.class,"_av_proportion_max.csv"))) #change label

write.csv(piv.meta, 
          file = file.path(outPath,paste(my.class,"_metadata.csv"))) #change label




```


