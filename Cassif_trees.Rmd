---
title: "Classification Trees"
output: html_notebook
---
## Libraries
```{r}
library(party)
library(rpart)
library(treeheatr)
```

## Arrange the data
Manually create a class column with the desired classification. Needs "resKR"
```{r}
data <- cbind(data.frame(class = NA), sub.coredata)

# Set number of classes needed
n<-7

# Make reclassification table
reclassify <- data.frame(level=c(1,4,5,5,3,3,3),
                         class=c(3,18,38,39,8,11,10),
                         new_class=sprintf("KR%s",seq(1:n)))

# Reclassify
for(i in 1:n){
  data[getsamplesingrp(resKR,reclassify$level[i],reclassify$class[i]),"class"]<-as.character(reclassify$new_class[i])
}

table(data$class)
```

## Parameters
```{r}
predictors <- paste(colnames(data)[-1], collapse="+")
fmla <- as.formula(paste("class", predictors,sep="~"))
```

## Fit tree
```{r}
# Fit full tree
tree_full <- rpart(fmla,
                   data=data,
                   method="class",
                   control=rpart.control(xval = 10,
                                         minbucket = 2, cp = 0)
)

# Select pruning depth (complexity paramter)
cp.select <- function(big.tree) {
  min.x <- which.min(big.tree$cptable[, 4]) #column 4 is xerror
  for(i in 1:nrow(big.tree$cptable)) {
    if(big.tree$cptable[i, 4] < big.tree$cptable[min.x, 4] + big.tree$cptable[min.x, 5]) return(big.tree$cptable[i, 1]) 
  }
}

cp <-cp.select(tree_full)

# Prune Tree
tree_full_pruned <- rpart(fmla,
                          data=data,
                          method="class",
                          control=rpart.control(xval = 10,
                                                minbucket = 2, cp = cp))

tree_full_pruned$variable.importance

```

## Plot it
```{r}

```
