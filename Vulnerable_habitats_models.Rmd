---
title: "Modeling"
output: html_notebook
---

## Libraries
```{r}
library(raster)
library(rgdal)
library(partykit)
library(party)

library(spatstat)
library(maptools)

library(usdm)
library(vegan)
library(glmnet)
```

## Predictors
```{r}
pred
```

## Make the response into a spatial object
```{r}
resp = "3031"
resp_spat <- respdf %>%
  rownames_to_column(var = "SampID")%>%
  left_join(sample_info)%>%
  select(SampID, resp, x_coord, y_coord)
resp_spat <-  SpatialPointsDataFrame(coords = resp_spat[,c(3,4)],
                                      data = resp_spat,
                                      proj4string = CRS("+proj=utm +zone=33 +datum=WGS84 +units=m +no_defs"))
```

## Reduce the dataset
Some species/taxa have very limited distributions. It may be a good idea to eliminate absence points that are too far away from any presence point
```{r}
## Select a subset of stations from the core distribution area(s) (code by RS)

# Step 1 - split into presence and absence points
abs<- subset(resp_spat, X3031==0)
pres<- subset(resp_spat, X3031>0)

# prevalence check
prev_1 <- length(pres)/length(resp_spat)

# Step 2 - find the distance to the nearest presence point of each absence point
absppp<- as(abs, "ppp")
presppp<-as(pres, "ppp")

dists<-nncross(absppp, presppp) # gives column dist (distance) and which (# of nearest presence point)

## if you want to check the distribution
#dist_ord<-dists[order(dists$dist),]
#plot(dist_ord$dist)

# Step 3 - find quartiles
qdist<-quantile(dists$dist,probs = seq(0, 1, 1/2)) # can modify the probs to change the number of divisions
lowQ<-qdist[[1]] # do not eliminate close ones
hiQ<-qdist[[2]]

# Step 4 - subset absences to exclude extreme quartiles
sel<-which((dists$dist>lowQ) & (dists$dist<hiQ))
sel.abs<-abs[sel, ]

## OUTPUT 
# Step 5 - combine with presences into output shapefile
resp_spat_sel<-rbind(pres,sel.abs)

# (prevalence check)
prev2<- length(pres)/length(resp_spat_sel)

prev2
```

## Extract values
```{r}
r <- resp_spat_sel
#r <- resp_spat

e <- raster::extract(pred, r)
v <- e %>% data.frame(cbind(r)) %>% mutate(landscape = factor(landscape)) %>% select(-contains("coord"))
str(v)
```
## Variable selection
I don't think this is very important right now - all I care about is spatial predictions - but oh well
```{r}
fmla <- as.formula(paste(paste0("X",resp,"~"), 
                         paste(colnames(v)[1:(which(colnames(v)=="X")-1)], collapse= "+"))) # all predictors
m0 <- cforest(fmla,
                      data=v, # all observations 
                      control = cforest_unbiased(ntree=1000,mtry = 3))
fmla
```

### Check which variables are important at explaining presence/absence
```{r}
# Make a predictor-only matrix and a response-only vector, and also, leave only complete cases in there
x0 <- v %>% select(-c(paste0("X",resp), optional)) %>% filter(complete.cases(.))
cc <- x0$SampID

y <- v %>% filter(SampID %in% cc) %>%
  select(paste0("X",resp)) %>%
  pull()
  
y <- as_factor(decostand(y,method="pa"))

x <- x0 %>% select(-SampID) %>% data.matrix()

# Model coefficients
cvfit = cv.glmnet(x, y,family="binomial",type.measure="auc")
coef(cvfit, s = "lambda.1se")
```

### Check which variables are correlated to each other
```{r}
vset <- vifstep(data.frame(x), th=12)
vset@excluded
```

### Check overall variable importance of remaining variables
```{r}
x_new <- x %>% 
  data.frame() %>%
  select(-vset@excluded) %>%
  data.matrix()

fmla1 <- as.formula(paste(paste0("X",resp,"~"), 
                          paste(colnames(x_new), collapse= "+")))

dotplot(sort(varimp(cforest(fmla1,
                            data=v, # all observations 
                            control = cforest_unbiased(ntree=1000,mtry = 3)))), xlab="Variable Importance", panel = function(x,y){ 
  panel.dotplot(x, y, col='darkblue', pch=16, cex=1.1) 
  panel.abline(v=abs(min(vi)), col='red', 
               lty='longdash', lwd=2
  )
})  
```
## Best model
A bit manual. Select the top variables according to variable importance making sure that they include the ones selected by glmnet (lasso?). This is the best because it's the simplest
```{r}
var <- sort(varimp(cforest(fmla1,
                            data=v, # all observations 
                            control = cforest_unbiased(ntree=1000,mtry = 3))),decreasing=TRUE)
fmlabest <- as.formula(paste(paste0("X",resp,"~"), 
                          paste(names(var[1:9]), collapse= "+")))
fmlabest
```

